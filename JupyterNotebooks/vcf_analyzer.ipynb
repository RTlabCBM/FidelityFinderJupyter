{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6anEqhZAZhEnCae5aRvVj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **VCF analyzer from https://github.com/friburgo-moc/FidelityFinder**\n","\n","File format required: VCFv4.x"],"metadata":{"id":"SLrkea_e63md"}},{"cell_type":"code","source":["#@markdown # Upload your VCF file\n","from google.colab import files\n","uploaded = files.upload()\n","vcf_file = list(uploaded.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"BMdf-oBZ5Tc3","executionInfo":{"status":"ok","timestamp":1692704961300,"user_tz":-120,"elapsed":9698,"user":{"displayName":"Friburgo Moc","userId":"01414597796276591985"}},"outputId":"ba24d55f-76d9-43d5-8d92-34deb3404ea7","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-484469cd-9018-443f-a5a5-7e76d1dac7cb\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-484469cd-9018-443f-a5a5-7e76d1dac7cb\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving RT_VarN.vcf to RT_VarN.vcf\n"]}]},{"cell_type":"code","source":["#@markdown # Input parameters\n","#@markdown Assign the corresponding values to the following parameters\n","consensus_number = 252 #@param {type:\"number\"}\n","min_pos = 62 #@param {type:\"number\"}\n","max_pos = 526 #@param {type:\"number\"}\n","output_prefix = \"sample_name \" #@param {type:\"string\"}"],"metadata":{"id":"zM2y1t4y5w2x","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown # Main program\n","\n","!pip install xlsxwriter\n","# Imports\n","import re\n","import os\n","import sys\n","import pandas as pd\n","import xlsxwriter\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import math\n","\n","\n","__doc__ = \"\"\"\n","SYNOPSIS\n","    Python script to find variants in VCF files. Creates an excel file with different data (table with variants, total number of variants, mutation rate...) and 3 graphs showing the distribution of variants in the reference sequence, the distribution of indels and a heatmap with the types of SNPs (if any).\n","\n","AUTHOR\n","\n","    Javier Martínez del Río    <javier.martinez@cbm.csic.es>\n","\n","\"\"\"\n","\n","\n","## Functions\n","##----------\n","\n","def help():\n","    print(globals()['__doc__'])\n","    sys.exit(1)\n","\n","def show_error_message(message):\n","    \"\"\"Gives an error message\"\"\"\n","    print(\"\\tERROR: {}\\n\".format(message))\n","    help()\n","    sys.exit(1)\n","\n","def convert_cigar_to_string(cadena):\n","    # Simplifies CIGAR strings to show only letters. For example, converts CIGAR \"1X\" to \"X\" or CIGAR \"2X2M\" to \"XXMM\".  Useful for counting type of substitutions in a simpler way.\n","    resultado = re.sub(r'(\\d+)([MDIX])', lambda match: match.group(2) * int(match.group(1)), cadena)\n","    return resultado\n","\n","def correct_excessive_matches(row):\n","    # Removes redundant letters \"M\" (matches) that can be generated in CIGARS. For example, a CIGAR of type \"2M2X3M\" becomes \"2X\". In addition, the convert_cigar_to_string function is used to simplify the CIGAR to \"XX\". When redudant letters \"M\" are found, the data in the REF and ALT columns are also corrected accordingly.\n","    new_cigar = convert_cigar_to_string(row[\"CIGAR\"])\n","    excessive_matches_at_start = 0\n","    excessive_matches_at_end = 0\n","    while new_cigar.startswith(\"M\") and not new_cigar[1:].startswith(\"D\") and not new_cigar[1:].startswith(\"I\"):\n","        new_cigar = new_cigar[1:]\n","        excessive_matches_at_start += 1\n","    while new_cigar.endswith(\"M\") and not new_cigar[:-1].endswith(\"D\") and not new_cigar[:-1].endswith(\"I\"):\n","        new_cigar = new_cigar[:-1]\n","        excessive_matches_at_end += 1\n","    row[\"POS\"] = row[\"POS\"] + excessive_matches_at_start\n","    if excessive_matches_at_end > 0:\n","        row[\"REF\"] = row[\"REF\"][excessive_matches_at_start:-excessive_matches_at_end]\n","        row[\"ALT\"] = row[\"ALT\"][excessive_matches_at_start:-excessive_matches_at_end]\n","    else:\n","        row[\"REF\"] = row[\"REF\"][excessive_matches_at_start:]\n","        row[\"ALT\"] = row[\"ALT\"][excessive_matches_at_start:]\n","    row[\"CIGAR\"] = new_cigar\n","    return row\n","\n","def show_one_variant_per_row(dataframe):\n","    #Modifies dataframe to show one variant per row, instead of one position per row as is the case in the original VCF file\n","    new_rows = []\n","    for index, row in dataframe.iterrows():\n","        alternatives = row['ALT'].split(',')\n","        aos = row['AO'].split(',')\n","        cigars = row['CIGAR'].split(',')\n","        types = row['TYPE'].split(',')\n","        for n, alternative in enumerate(alternatives):\n","            new_row = [row['POS'], row['REF'], alternatives[n], int(aos[n]), cigars[n], types[n]]\n","            new_rows.append(new_row)\n","    new_dataframe = pd.DataFrame(new_rows, columns=dataframe.columns)\n","    return new_dataframe\n","\n","def create_dataframe_from_vcf(vcf_file, consensus_number, min_pos, max_pos):\n","  sequence_length = max_pos - min_pos + 1\n","  # Create a pandas dataframe from the input vcf file. We also need the number of consensus and the length of the sequence to calculate the rate of the variants.\n","  df = pd.read_csv(vcf_file, sep='\\t', comment='#', header=None)\n","  df.columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'unknown']\n","  df = df[df['ALT'] != \".\"] #We drop positions with no variants\n","  if len(df) < 1:\n","    print(\"VCF file has no variants\")\n","  df['AO'] = df['INFO'].str.extract(r'AO=([\\d,]+)').fillna(0) #We extract \"AO\" from the INFO column (##INFO=<ID=AO,Number=A,Type=Integer,Description=\"Alternate allele observations, with partial observations recorded fractionally\">)\n","  df['CIGAR'] = df['INFO'].str.extract(r'CIGAR=(.*?);') #We extract \"CIGAR\" from the INFO column (##INFO=<ID=CIGAR,Number=A,Type=String,Description=\"The extended CIGAR representation of each alternate allele, with the exception that '=' is replaced by 'M' to ease VCF parsing.  Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.\">)\n","  df['TYPE'] = df['INFO'].str.extract(r'TYPE=(.*?)(?:;|$)') #We extract \"TYPE\" from the INFO column (##INFO=<ID=TYPE,Number=A,Type=String,Description=\"The type of allele, either snp, mnp, ins, del, or complex.\">)\n","  df = df[['POS', \"REF\", \"ALT\", \"AO\", \"CIGAR\", \"TYPE\"]]\n","  df = show_one_variant_per_row(df)\n","  df = df.apply(correct_excessive_matches, axis=1).sort_values(\"POS\")\n","  df = df[(df['POS'] >= min_pos) & (df['POS'] <= max_pos)] #We filter the df according to the input parameters \"min_pos\" and \"max_pos\"\n","  df['AO_rate'] = df['AO'] / (consensus_number * sequence_length) # We add a column with the AO rate of each variant\n","  return df\n","\n","def create_dict_snp_types(dataframe):\n","  # Creates a dictionary with each type of substitution (SNP variants). Input dataframe: dataframe created using create_dataframe_from_vcf function.\n","  dict_snp_types={}\n","  def count_snp_types(row):\n","    snp_type = row[\"REF\"] + row[\"ALT\"]\n","    try:\n","      dict_snp_types[snp_type] += row[\"AO\"]\n","    except:\n","      dict_snp_types[snp_type] = row[\"AO\"]\n","  dataframe[dataframe[\"TYPE\"]==\"snp\"].apply(count_snp_types, axis=1)\n","  return dict_snp_types\n","\n","def create_df_snp_types(dict_snp_types):\n","  # Creates a dataframe using the dictionary of snp_types obtained with create_dict_snp_types function\n","  # In the left part of the table we show the nucleotides in the reference sequence and in the upper part of the table the nucleotides for which they are substituted.\n","  bases = ['G', 'A', 'T', 'C']\n","  table = {}\n","  for base in bases:\n","      table[base] = {}\n","      for otra_base in bases:\n","          table[base][otra_base] = None\n","  for key, value in dict_snp_types.items():\n","      base1 = key[1]\n","      base2 = key[0]\n","      table[base1][base2] = str(value)\n","  df_snp_types = pd.DataFrame(table)\n","  return df_snp_types\n","\n","#def find_numeric_columns(df):\n","#    numeric_columns  = df.select_dtypes(include=['int64', 'float64']).columns\n","#    return numeric_columns\n","\n","def extract_data_from_dataframe(dataframe, output_file_name, consensus_number, min_pos, max_pos):\n","  # Creates an excel file with different data (table with variants, total number of variants, mutation rate...) and 3 graphs showing the distribution of variants in the reference sequence, the distribution of indels and a heatmap with the types of SNPs (if any).\n","  # Input dataframe: dataframe created using create_dataframe_from_vcf function.\n","\n","  #Extract data\n","  sequence_length = max_pos - min_pos + 1\n","  dict_snp_types = create_dict_snp_types(dataframe)\n","  if all(math.isnan(value) for value in dict_snp_types.values()): #if all values dict_snp_types are \"nan\", we assign the value 0 to each substitution type\n","    dict_snp_types = {'TC': 0, 'TG': 0, 'AC': 0, 'AG': 0, 'AT': 0, 'GA': 0, 'GC': 0, 'GT': 0, 'CT': 0, 'CA': 0, 'TA': 0, 'CG': 0}\n","  #total_nan_values = dataframe.isna().sum().sum()\n","  dataframe = dataframe.dropna()\n","  total_unique_variants = len(dataframe.index)\n","  total_variants = dataframe[\"AO\"].sum()\n","  total_snp = dataframe[dataframe[\"TYPE\"]==\"snp\"][\"AO\"].sum()\n","  total_transitions = sum(dict_snp_types.get(key, 0) for key in [\"AG\", \"GA\", \"CT\", \"TC\"])\n","  total_transversions = total_snp - total_transitions\n","  total_ins = dataframe[dataframe[\"TYPE\"]==\"ins\"][\"AO\"].sum()\n","  total_del = dataframe[dataframe[\"TYPE\"]==\"del\"][\"AO\"].sum()\n","  total_indels = total_ins + total_del\n","  total_mnp = dataframe[dataframe[\"TYPE\"]==\"mnp\"][\"AO\"].sum()\n","  total_complex = dataframe[dataframe[\"TYPE\"]==\"complex\"][\"AO\"].sum()\n","  try:\n","      proportion_snp = round((total_snp / total_variants * 100), 2)\n","      proportion_transitions = round((total_transitions / total_variants * 100), 2)\n","      proportion_transversions = round((total_transversions / total_variants * 100), 2)\n","      proportion_indels = round((total_indels / total_variants * 100), 2)\n","      proportion_ins = round((total_ins / total_variants * 100), 2)\n","      proportion_del = round((total_del / total_variants * 100), 2)\n","      proportion_mnp = round((total_mnp / total_variants * 100), 2)\n","      proportion_complex = round((total_complex / total_variants * 100), 2)\n","      mutation_rate = total_variants/(sequence_length*consensus_number)\n","  except ZeroDivisionError as e:\n","      print(\"Error: Cannot divide by zero\")\n","      proportion_snp = 0\n","      proportion_transitions = 0\n","      proportion_transversions = 0\n","      proportion_indels = 0\n","      proportion_ins = 0\n","      proportion_del = 0\n","      proportion_mnp = 0\n","      proportion_complex = 0\n","      mutation_rate = 0\n","\n","  #Group data in dictionaries\n","  basic_data = {\n","      'Total consensus': [consensus_number],\n","      'Sequence length': [sequence_length],\n","      'Total Variants': [total_variants],\n","      'Total Unique Variants': [total_unique_variants],\n","      'Mutation Rate': [mutation_rate]\n","  }\n","  total_data = {\n","      'Total Variants': [total_variants],\n","      'Total SNP': [total_snp],\n","      'Total Transitions': [total_transitions],\n","      'Total Transversions': [total_transversions],\n","      'Total INS': [total_ins],\n","      'Total DEL': [total_del],\n","      'Total Indels': [total_indels],\n","      'Total MNP': [total_mnp],\n","      'Total Complex': [total_complex]\n","  }\n","  proportion_data = {\n","      'Proportion SNP': [proportion_snp],\n","      'Proportion SNP Transitions': [proportion_transitions],\n","      'Proportion SNP Transversions': [proportion_transversions],\n","      'Proportion Indels': [proportion_indels],\n","      'Proportion INS': [proportion_ins],\n","      'Proportion DEL': [proportion_del],\n","      'Proportion MNP': [proportion_mnp],\n","      'Proportion complex': [proportion_complex]\n","  }\n","\n","  #Create dataframes\n","  df_grouped_by_position = dataframe.groupby('POS')[['AO', 'AO_rate']].sum().reset_index().sort_values('POS')\n","  df_indels = dataframe[(dataframe[\"TYPE\"] == \"ins\") | (dataframe[\"TYPE\"] == \"del\")]\n","  df_grouped_indels = df_indels.groupby('POS')[['AO', 'AO_rate']].sum().reset_index().sort_values('POS') # Group indels' AO values by position and sum them up\n","  df_snps = dataframe[(dataframe[\"TYPE\"] == \"snp\")]\n","  df_grouped_snp = df_snps.groupby('POS')[['AO', 'AO_rate']].sum().reset_index().sort_values('POS')\n","  df_snp_types = create_df_snp_types(dict_snp_types)\n","  df_basic_data = pd.DataFrame(basic_data)\n","  df_total_data = pd.DataFrame(total_data)\n","  df_proportion_data = pd.DataFrame(proportion_data)\n","\n","\n","  # Create excel file from dataframes\n","  global excel_file\n","  excel_file = output_file_name + '.xlsx'\n","  with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n","      dataframe.to_excel(writer, sheet_name='Raw data', index=False)\n","      df_grouped_by_position.to_excel(writer, sheet_name='Variants per position', index=False)\n","      df_indels.to_excel(writer, sheet_name='Indels', index=False)\n","      df_grouped_indels.to_excel(writer, sheet_name='Indels per position', index=False)\n","      df_snps.to_excel(writer, sheet_name='SNPs', index=False)\n","      df_grouped_snp.to_excel(writer, sheet_name='SNPs per position', index=False)\n","      df_snp_types.to_excel(writer, sheet_name='SNP types', index=True)\n","      df_basic_data.to_excel(writer, sheet_name='Error rate', index=False)\n","      df_total_data.to_excel(writer, sheet_name='Total data', index=False)\n","      df_proportion_data.to_excel(writer, sheet_name='Proportion data', index=False)\n","\n","\n","  # Save dataframe with raw data as csv file\n","  global csv_file\n","  csv_file = output_file_name + \".csv\"\n","  dataframe.to_csv(csv_file, index=False)\n","\n","\n","  #Create heatmap image of the SNP types (shown as percentages)\n","  plt.clf()\n","  total_sum = sum(dict_snp_types.values())\n","  if total_sum != 0:\n","    dict_snp_types_percentage = {key: (value / total_sum) * 100 for key, value in dict_snp_types.items()}\n","  else:\n","    dict_snp_types_percentage = dict_snp_types\n","  df_table = create_df_snp_types(dict_snp_types_percentage)\n","  plt.figure(figsize=(6, 4))\n","  sns.heatmap(df_table.astype(float), cmap='coolwarm', annot=True, fmt=\".1f\", cbar_kws={'label': '%'})\n","  plt.gca().xaxis.set_label_position('top')\n","  plt.xlabel('Nucleotide substitutions')\n","  plt.ylabel('Reference nucleotides')\n","  plt.suptitle(output_file_name)\n","  plt.subplots_adjust(top=0.80)\n","  plt.gca().tick_params(axis='x', top=True, bottom=False, labeltop=True, labelbottom=False) #Adjust position of ticks and x-axis labels\n","  plt.text(0.5, -0.1, f\"Total number of substitutions: {total_sum}\", transform=plt.gca().transAxes, ha='center') #Add total number of substitutions as text in the image\n","  global name_heatmap_snp_types\n","  name_heatmap_snp_types = output_file_name + 'heatmap_snp_types.png'\n","  plt.savefig(name_heatmap_snp_types)\n","  plt.close()\n","\n","  #Create graph with the distribution of variants in the reference sequence\n","  plt.clf()\n","  grouped_df = dataframe.groupby('POS')['AO'].sum().reset_index().sort_values('POS') # Group AO values by position and sum them up\n","  colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n","  plt.bar(grouped_df['POS'], grouped_df['AO'], color=colors[0])\n","  plt.xlabel('Position')\n","  plt.ylabel('Number of variants')\n","  plt.title('Variants distribution')\n","  plt.suptitle(output_file_name)\n","  mean = grouped_df['AO'].mean()\n","  plt.axhline(y=mean, color=colors[1], linestyle='--', label=f'Mean ({mean:.2f})') # Add a horizontal line to mark the mean of variants in positions with variants\n","  median = grouped_df['AO'].median()\n","  plt.axhline(y=median, color=colors[2], linestyle='--', label=f'Median ({median:.2f})') # Add a horizontal line to mark the median of variants in positions with variants\n","  plt.legend(['Mean ({:.2f})'.format(mean), 'Median ({:.2f})'.format(median), 'Variants'], loc='upper right')\n","  try:\n","    plt.ylim([0, grouped_df['AO'].max()*1.1]) # Set y-axis limits\n","  except Exception:\n","    pass\n","  plt.xlim(min_pos -1, max_pos + 1) # Set x-axis limits\n","  global name_variants_graph\n","  name_variants_graph = output_file_name + \"_variants_distribution.png\"\n","  plt.savefig(name_variants_graph)\n","  plt.close()\n","\n","  #Create graph with the distribution of indel variants in the reference sequence\n","  plt.clf()\n","  colors = ['red', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n","  plt.bar(df_grouped_indels['POS'], df_grouped_indels['AO'], color=colors[0])\n","  plt.xlabel('Position')\n","  plt.ylabel('Number of variants')\n","  plt.title('Indel variants distribution')\n","  plt.suptitle(output_file_name)\n","  mean = df_grouped_indels['AO'].mean()\n","  plt.axhline(y=mean, color=colors[1], linestyle='--', label=f'Mean ({mean:.2f})') # Add a horizontal line to mark the mean of variants in positions with variants\n","  median = df_grouped_indels['AO'].median()\n","  plt.axhline(y=median, color=colors[2], linestyle='--', label=f'Median ({median:.2f})') # Add a horizontal line to mark the median of variants in positions with variants\n","  plt.legend(['Mean ({:.2f})'.format(mean), 'Median ({:.2f})'.format(median), 'Indels'], loc='upper right')\n","  try:\n","    plt.ylim([0, df_grouped_indels['AO'].max()*1.1]) # Set y-axis limits\n","  except Exception:\n","    pass\n","  plt.xlim(min_pos -1, max_pos + 1) # Set x-axis limits\n","  # Descargar la gráfica\n","  global indels_graph\n","  indels_graph = output_file_name + \"_indels_distribution.png\"\n","  plt.savefig(indels_graph)\n","  plt.close()\n","\n","\n","\n","## Main program\n","##-------------\n","\n","def main():\n","\n","    print(\"\\tStep 1 => Creating dataframe\")\n","    try:\n","        dataframe_from_vcf = create_dataframe_from_vcf(vcf_file, consensus_number, min_pos, max_pos)\n","    except Exception as e:\n","        show_error_message(f'VCF file could not be analysed: Problem when trying to convert VCF file to pandas dataframe:\\n{e}')\n","    print(\"\\tStep 1 done\\n\")\n","\n","    print(\"\\tStep 2 => Extracting data from dataframe and drawing graphs\")\n","    try:\n","        extract_data_from_dataframe(dataframe_from_vcf, output_prefix, consensus_number, min_pos, max_pos)\n","    except Exception as e:\n","        show_error_message(f'There was a problem with the extract_data_from_dataframe function:\\n{e}')\n","    print(\"\\tStep 2 done\\n\")\n","\n","    print(\"\\tJOB DONE!\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCGVliug41xO","executionInfo":{"status":"ok","timestamp":1692704969775,"user_tz":-120,"elapsed":5631,"user":{"displayName":"Friburgo Moc","userId":"01414597796276591985"}},"outputId":"454eb952-aa69-40ff-9587-c8a436f546c5","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.1.2)\n","\tStep 1 => Creating dataframe\n","\tStep 1 done\n","\n","\tStep 2 => Extracting data from dataframe and drawing graphs\n","\tStep 2 done\n","\n","\tJOB DONE!\n"]}]},{"cell_type":"code","source":["#@markdown # Download files\n","files.download(excel_file)\n","files.download(csv_file)\n","files.download(name_heatmap_snp_types)\n","files.download(name_variants_graph)\n","files.download(indels_graph)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"KA_A997A6_Y2","executionInfo":{"status":"ok","timestamp":1692704971296,"user_tz":-120,"elapsed":5,"user":{"displayName":"Friburgo Moc","userId":"01414597796276591985"}},"outputId":"18123e5c-9eef-42c7-be10-b4c7c453f264","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_15767311-dbbf-4419-95c8-d8231cb49b83\", \"sample_name .xlsx\", 20301)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e41e2774-08af-4805-ab08-9e1c745fef05\", \"sample_name .csv\", 4411)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7dbae130-1ef2-4ccd-a693-7bd00369bb8e\", \"sample_name heatmap_snp_types.png\", 25426)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e8299098-348d-4139-a69a-46cf2b988016\", \"sample_name _variants_distribution.png\", 25416)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_75a5f4db-25c9-40eb-b018-0f2cbf072992\", \"sample_name _indels_distribution.png\", 23697)"]},"metadata":{}}]}]}