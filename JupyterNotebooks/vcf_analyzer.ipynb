{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLrkea_e63md"
      },
      "source": [
        "# **vcf_analyzer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python script to find variants in VCF files.\n",
        "\n",
        "It creates an excel file with different data (table with variants, total number of variants, mutation rate...) and 3 graphs showing the distribution of variants in the reference sequence, the distribution of indels and a heatmap with the types of SNPs (if any).\n",
        "\n",
        "For additional details, please refer to the GitHub repository: https://github.com/RTlabCBM/FidelityFinder"
      ],
      "metadata": {
        "id": "to3lW_AUoi_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BMdf-oBZ5Tc3"
      },
      "outputs": [],
      "source": [
        "#@markdown # Upload your VCF file\n",
        "#@markdown File format required: VCFv4.1 generated by freebayes 0.9.21\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "input_file = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zM2y1t4y5w2x"
      },
      "outputs": [],
      "source": [
        "#@markdown # Input parameters\n",
        "#@markdown Assign the corresponding values to the following parameters:\n",
        "#@markdown - **number of consensus** sequences used to obtain variants [required]\n",
        "consensus_number = 107052 #@param {type:\"number\"}\n",
        "#@markdown - **first position** of the reference sequence used to quantify mutations [required]\n",
        "min_pos = 23 #@param {type:\"number\"}\n",
        "#@markdown - **last position** of the reference sequence used to quantify mutations [required]\n",
        "max_pos = 492 #@param {type:\"number\"}\n",
        "#@markdown - **output prefix**\n",
        "output_prefix = \"undefined\" #@param {type:\"string\"}\n",
        "#@markdown - **maximum percentage of consensus sequences with a particular variant** (0-100). Variants exceeding this frequency will be excluded from the result.\n",
        "#@markdown  - variant_freq_threshold=100 will not exclude any variant and variant_freq_threshold=0 will exclude all variants.\n",
        "#@markdown  - variant_freq_threshold=95 is recommended\n",
        "variant_freq_threshold = 95 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Optional input parameters\n",
        "#@markdown Optional parameters to include information in the output files. Do not run this cell if the default values are desired.\n",
        "#@markdown - **frequency of the barcode with the maximum frequency** [default=None]\n",
        "max_barcode = 0 #@param {type:\"number\"}\n",
        "#@markdown - **lower cut-off** of sequences per barcode used previously [default=None]\n",
        "cutoff = 0 #@param {type:\"number\"}\n",
        "#@markdown - **threshold** used previously to construct consensus sequences [default=None]\n",
        "threshold = 0 #@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MiEk4w_ruyX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCGVliug41xO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Main program\n",
        "__file__ = \"main_program\"\n",
        "\n",
        "\n",
        "!pip install xlsxwriter==3.1.9\n",
        "\n",
        "\n",
        "__doc__ = \"\"\"\n",
        "SYNOPSIS\n",
        "    Python script to find variants in VCF files.\n",
        "    It creates an excel file with different data (table with variants, total number of variants, mutation rate...)\n",
        "    and 3 graphs showing the distribution of variants in the reference sequence, the distribution of indels and a heatmap with the types of SNPs (if any).\n",
        "\n",
        "    This script is an adaptation of the original program to be run on Google Colab.\n",
        "\n",
        "DESCRIPTION\n",
        "\n",
        " Parameters:\n",
        "    input_file\t                vcf file [required]\n",
        "    consensus_number\t          number of consensus sequences used to obtain variants [required]\n",
        "    min_pos                     first position of the reference sequence used to quantify mutations [required]\n",
        "    max_pos                     last position of the reference sequence used to quantify mutations [required]\n",
        "    output_prefix\t\t            output prefix [default='undefined']\n",
        "    max_barcode                 frequency of the barcode with the maximum frequency [default=None]\n",
        "    cutoff                      lower cut-off of sequences per barcode used previously [default=None]\n",
        "    threshold                   threshold used previously to construct consensus sequences [default=None]\n",
        "    variant_freq_threshold      maximum percentage of consensus sequences with a particular variant (0-100). Variants exceeding this frequency will be excluded from the result [default=95]\n",
        "                                variant_freq_threshold=100 will not exclude any variant and variant_freq_threshold=0 will exclude all variants.\n",
        "\n",
        " Input file:\n",
        " The input file must be in VCF format (VCFv4.1) generated by freebayes version 0.9.21.\n",
        "\n",
        " Note: This script was tested using xlsxwriter version 3.1.9. You can install it by running:\n",
        "    pip install xlsxwriter==3.1.9\n",
        "\n",
        "\n",
        "AUTHOR\n",
        "\n",
        "    Javier Martínez del Río    (javier.martinez@cbm.csic.es; javier.mardelrio@gmail.com)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "__version__ = 'v1.0.0'\n",
        "\n",
        "\n",
        "## Imports\n",
        "##----------\n",
        "\n",
        "import re\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Functions\n",
        "##----------\n",
        "\n",
        "def send_error_message(message):\n",
        "    \"\"\"Gives an error message\"\"\"\n",
        "    print(\"\\tERROR: {}\\n\".format(message))\n",
        "    help()\n",
        "    sys.exit(1)\n",
        "\n",
        "def convert_cigar_to_string(cigar_string):\n",
        "    \"\"\"\n",
        "    Simplifies CIGAR strings to show only letters. Useful for counting types of substitutions in a simpler way.\n",
        "\n",
        "    Parameters:\n",
        "        - cigar_string (str): The input CIGAR string that represents a sequence alignment. It consists of a series of letters, each with a length, such as \"2X2M\".\n",
        "\n",
        "    Returns:\n",
        "        - simpler_cigar_string (str): A simplified version of the input CIGAR string, where digits and their associated operation letters are expanded. For example, \"2X2M\" becomes \"XXMM\".\n",
        "    \"\"\"\n",
        "    simpler_cigar_string = re.sub(r'(\\d+)([MDIX])', lambda match: match.group(2) * int(match.group(1)), cigar_string)\n",
        "    return simpler_cigar_string\n",
        "\n",
        "def correct_excessive_matches(row):\n",
        "    \"\"\"\n",
        "    Removes redundant letters \"M\" (matches) that can be generated in CIGARS. For example, a CIGAR of type \"2M2X3M\" becomes \"2X\".\n",
        "    In addition, the convert_cigar_to_string function is used to simplify the CIGAR to \"XX\".\n",
        "\n",
        "    Parameters:\n",
        "        - row (pd.Series): A Pandas Series representing a row of a DataFrame containing information about a genomic variant.\n",
        "                      It should have columns 'POS', 'REF', 'ALT', and 'CIGAR'.\n",
        "\n",
        "    Returns:\n",
        "        - row (pd.Series): The modified input row after removing excessive matches in the CIGAR string and adjusting the REF and ALT columns accordingly.\n",
        "    \"\"\"\n",
        "    # Simplify the CIGAR string using the convert_cigar_to_string function\n",
        "    new_cigar = convert_cigar_to_string(row[\"CIGAR\"])\n",
        "\n",
        "    # Count and remove excessive matches at the start of the CIGAR\n",
        "    excessive_matches_at_start = 0\n",
        "    while new_cigar.startswith(\"M\") and not new_cigar[1:].startswith(\"D\") and not new_cigar[1:].startswith(\"I\"):\n",
        "        new_cigar = new_cigar[1:]\n",
        "        excessive_matches_at_start += 1\n",
        "\n",
        "    # Count and remove excessive matches at the end of the CIGAR\n",
        "    excessive_matches_at_end = 0\n",
        "    while new_cigar.endswith(\"M\") and not new_cigar[:-1].endswith(\"D\") and not new_cigar[:-1].endswith(\"I\"):\n",
        "        new_cigar = new_cigar[:-1]\n",
        "        excessive_matches_at_end += 1\n",
        "\n",
        "    # Adjust the 'POS' column based on matches removed at the start\n",
        "    row[\"POS\"] = row[\"POS\"] + excessive_matches_at_start\n",
        "\n",
        "    # Adjust the 'REF' and 'ALT' columns based on matches removed at the end\n",
        "    if excessive_matches_at_end > 0:\n",
        "        row[\"REF\"] = row[\"REF\"][excessive_matches_at_start:-excessive_matches_at_end]\n",
        "        row[\"ALT\"] = row[\"ALT\"][excessive_matches_at_start:-excessive_matches_at_end]\n",
        "    else:\n",
        "        row[\"REF\"] = row[\"REF\"][excessive_matches_at_start:]\n",
        "        row[\"ALT\"] = row[\"ALT\"][excessive_matches_at_start:]\n",
        "\n",
        "    # Update the 'CIGAR' column with the modified CIGAR string\n",
        "    row[\"CIGAR\"] = new_cigar\n",
        "    return row\n",
        "\n",
        "def show_one_variant_per_row(dataframe):\n",
        "    \"\"\"\n",
        "    Modifies a DataFrame to represent one variant per row instead of one position per row, as is the case in the original VCF file.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe (pd.DataFrame): The input DataFrame containing genomic variant information. It is assumed to have columns like 'POS', 'REF', 'ALT', 'AO', 'CIGAR', and 'TYPE'.\n",
        "\n",
        "    Returns:\n",
        "    - new_dataframe (pd.DataFrame): A new DataFrame where each row corresponds to a specific variant, and information such as 'POS', 'REF', 'ALT', 'AO', 'CIGAR', and 'TYPE' is appropriately duplicated or split based on multiple alternatives.\n",
        "    \"\"\"\n",
        "    # Initialize an empty list to store rows for the new DataFrame\n",
        "    new_rows_list = []\n",
        "\n",
        "    # Iterate through each row in the original DataFrame and create a new row for each variant (alternative) from the original row\n",
        "    for index, row in dataframe.iterrows():\n",
        "        alternatives = row['ALT'].split(',')\n",
        "        aos = row['AO'].split(',')\n",
        "        cigars = row['CIGAR'].split(',')\n",
        "        types = row['TYPE'].split(',')\n",
        "        for n, alternative in enumerate(alternatives):\n",
        "            new_row = [row['POS'], row['REF'], alternatives[n], int(aos[n]), cigars[n], types[n]]\n",
        "            new_rows_list.append(new_row)\n",
        "\n",
        "    # Create a new DataFrame with the new rows\n",
        "    new_dataframe = pd.DataFrame(new_rows_list, columns=dataframe.columns)\n",
        "    return new_dataframe\n",
        "\n",
        "def create_dataframe_from_vcf(vcf_file, consensus_number, min_pos, max_pos, variant_frequency_threshold):\n",
        "    \"\"\"\n",
        "    Creates a pandas DataFrame from a VCF file, processes and filters the data.\n",
        "\n",
        "    Parameters:\n",
        "    - vcf_file (str): Path to the VCF file.\n",
        "    - consensus_number (int): Number of consensus sequences.\n",
        "    - min_pos (int): Minimum position to consider.\n",
        "    - max_pos (int): Maximum position to consider.\n",
        "    - variant_frequency_threshold (float): maximum percentage of consensus sequences with a particular variant. Variants exceeding this frequency will be excluded from the result\n",
        "\n",
        "    Returns:\n",
        "    - df (pd.DataFrame): Processed DataFrame with relevant variant information.\n",
        "    \"\"\"\n",
        "    # Calculate sequence length\n",
        "    sequence_length = max_pos - min_pos + 1\n",
        "\n",
        "    # Read VCF file into a DataFrame\n",
        "    try:\n",
        "      df = pd.read_csv(vcf_file, sep='\\t', comment='#', header=None)\n",
        "      df.columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'unknown']\n",
        "    except pd.errors.EmptyDataError:\n",
        "      print(\"WARNING: No data found in the VCF file.\")\n",
        "      df = pd.DataFrame(columns=['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'unknown'])\n",
        "\n",
        "    # Drop positions with no variants\n",
        "    df = df[df['ALT'] != \".\"]\n",
        "\n",
        "    # Extract relevant information from INFO column\n",
        "    df['AO'] = df['INFO'].str.extract(r'AO=([\\d,]+)').fillna(0) #We extract \"AO\" from the INFO column (##INFO=<ID=AO,Number=A,Type=Integer,Description=\"Alternate allele observations, with partial observations recorded fractionally\">)\n",
        "    df['CIGAR'] = df['INFO'].str.extract(r'CIGAR=(.*?);') #We extract \"CIGAR\" from the INFO column (##INFO=<ID=CIGAR,Number=A,Type=String,Description=\"The extended CIGAR representation of each alternate allele, with the exception that '=' is replaced by 'M' to ease VCF parsing.  Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.\">)\n",
        "    df['TYPE'] = df['INFO'].str.extract(r'TYPE=(.*?)(?:;|$)') #We extract \"TYPE\" from the INFO column (##INFO=<ID=TYPE,Number=A,Type=String,Description=\"The type of allele, either snp, mnp, ins, del, or complex.\">)\n",
        "\n",
        "    # Select relevant columns\n",
        "    df = df[['POS', \"REF\", \"ALT\", \"AO\", \"CIGAR\", \"TYPE\"]]\n",
        "\n",
        "    # Show one variant per row\n",
        "    df = show_one_variant_per_row(df)\n",
        "\n",
        "    # Correct excessive matches in CIGAR and update positions\n",
        "    df = df.apply(correct_excessive_matches, axis=1).sort_values(\"POS\")\n",
        "\n",
        "    # Filter DataFrame based on min_pos and max_pos\n",
        "    df = df[(df['POS'] >= min_pos) & (df['POS'] <= max_pos)]\n",
        "\n",
        "    # Calculate AO rate and variant frequency percentage\n",
        "    df['AO_rate'] = df['AO'] / (consensus_number * sequence_length) # We add a column with the AO rate of each variant\n",
        "    df['Variant frequency (%)'] = df['AO'] / consensus_number * 100 # We add a column with the % of consensus sequences with a variant\n",
        "\n",
        "    # Discard variants with high frequency based on value included in variant_frequency_threshold\n",
        "    df = df[df['Variant frequency (%)'] < variant_frequency_threshold]\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_dict_snp_types(dataframe):\n",
        "    \"\"\"\n",
        "    Creates a dictionary with counts for each type of substitution (SNP variants).\n",
        "\n",
        "    Parameters:\n",
        "        - dataframe (pd.DataFrame): Input dataframe created using the create_dataframe_from_vcf function.\n",
        "\n",
        "    Returns:\n",
        "        - dict_snp_types (dict): Dictionary containing SNP types as keys and their corresponding counts as values. Example: {\"AT\": 45, \"AG\": 32, ...}\n",
        "    \"\"\"\n",
        "    dict_snp_types={}\n",
        "    def count_snp_types(row):\n",
        "        snp_type = row[\"REF\"] + row[\"ALT\"]\n",
        "        try:\n",
        "            dict_snp_types[snp_type] += row[\"AO\"]\n",
        "        except:\n",
        "            dict_snp_types[snp_type] = row[\"AO\"]\n",
        "    dataframe[dataframe[\"TYPE\"]==\"snp\"].apply(count_snp_types, axis=1)\n",
        "    return dict_snp_types\n",
        "\n",
        "def create_df_snp_types(dict_snp_types):\n",
        "    \"\"\"\n",
        "    Creates a dataframe using the dictionary of snp_types obtained with create_dict_snp_types function.\n",
        "    In the left part of the table, we show the nucleotides in the reference sequence,\n",
        "    and in the upper part of the table, the nucleotides for which they are substituted.\n",
        "\n",
        "    Parameters:\n",
        "    - dict_snp_types (dict): Dictionary containing counts of SNP types.\n",
        "\n",
        "    Returns:\n",
        "    - df_snp_types (pd.DataFrame): DataFrame representing the SNP types table.\n",
        "    \"\"\"\n",
        "    bases = ['G', 'A', 'T', 'C']\n",
        "    table = {}\n",
        "    for base in bases:\n",
        "      table[base] = {}\n",
        "      for other_base in bases:\n",
        "          table[base][other_base] = None\n",
        "    for key, value in dict_snp_types.items():\n",
        "      base1 = key[1]\n",
        "      base2 = key[0]\n",
        "      table[base1][base2] = str(value)\n",
        "    df_snp_types = pd.DataFrame(table)\n",
        "    return df_snp_types\n",
        "\n",
        "def extract_data_from_dataframe(dataframe, output_prefix, consensus_number, min_pos, max_pos, max_barcode, cutoff, threshold):\n",
        "    global df_basic_data\n",
        "    \"\"\"\n",
        "    Creates an Excel file with different data (table with variants, total number of variants, error rate...),\n",
        "    a csv file with the table of variants,\n",
        "    2 graphs showing the distribution of variants and indel variants,\n",
        "    and a heatmap graph with the types of SNPs (if any).\n",
        "\n",
        "    Parameters:\n",
        "        - dataframe (pd.DataFrame): DataFrame created using create_dataframe_from_vcf function.\n",
        "        - output_prefix (str): Prefix for output files.\n",
        "        - consensus_number (int): Number of consensus sequences.\n",
        "        - min_pos (int): Minimum position analyzed.\n",
        "        - max_pos (int): Maximum position analyzed.\n",
        "        - max_barcode (int): Maximum barcode frequency.\n",
        "        - cutoff (int): Cutoff used.\n",
        "        - threshold (float): Threshold used.\n",
        "\n",
        "    Returns:\n",
        "        - excel_file (str): Path to the Excel file.\n",
        "        - csv_file (str): Path to the CSV file.\n",
        "        - variants_graph (str): Path to the variants distribution graph.\n",
        "        - indels_graph (str): Path to the indels distribution graph.\n",
        "        - heatmap_snp_types_graph (str): Path to the SNP types heatmap graph.\n",
        "    \"\"\"\n",
        "    #EXTRACT DATA\n",
        "    sequence_length = max_pos - min_pos + 1\n",
        "    dict_snp_types = create_dict_snp_types(dataframe)\n",
        "    #if all values dict_snp_types are \"nan\", assign the value 0 to each substitution type\n",
        "    if all(math.isnan(value) for value in dict_snp_types.values()):\n",
        "        dict_snp_types = {'TC': 0, 'TG': 0, 'AC': 0, 'AG': 0, 'AT': 0, 'GA': 0, 'GC': 0, 'GT': 0, 'CT': 0, 'CA': 0, 'TA': 0, 'CG': 0}\n",
        "    dataframe = dataframe.dropna()\n",
        "    total_unique_variants = len(dataframe.index)\n",
        "    total_variants = dataframe[\"AO\"].sum()\n",
        "    total_snp = dataframe[dataframe[\"TYPE\"]==\"snp\"][\"AO\"].sum()\n",
        "    total_transitions = sum(dict_snp_types.get(key, 0) for key in [\"AG\", \"GA\", \"CT\", \"TC\"])\n",
        "    total_transversions = total_snp - total_transitions\n",
        "    total_ins = dataframe[dataframe[\"TYPE\"]==\"ins\"][\"AO\"].sum()\n",
        "    total_del = dataframe[dataframe[\"TYPE\"]==\"del\"][\"AO\"].sum()\n",
        "    total_indels = total_ins + total_del\n",
        "    total_mnp = dataframe[dataframe[\"TYPE\"]==\"mnp\"][\"AO\"].sum()\n",
        "    total_complex = dataframe[dataframe[\"TYPE\"]==\"complex\"][\"AO\"].sum()\n",
        "    try:\n",
        "        proportion_snp = round((total_snp / total_variants * 100), 2)\n",
        "        proportion_transitions = round((total_transitions / total_variants * 100), 2)\n",
        "        proportion_transversions = round((total_transversions / total_variants * 100), 2)\n",
        "        proportion_indels = round((total_indels / total_variants * 100), 2)\n",
        "        proportion_ins = round((total_ins / total_variants * 100), 2)\n",
        "        proportion_del = round((total_del / total_variants * 100), 2)\n",
        "        proportion_mnp = round((total_mnp / total_variants * 100), 2)\n",
        "        proportion_complex = round((total_complex / total_variants * 100), 2)\n",
        "        mutation_rate = total_variants/(sequence_length*consensus_number)\n",
        "    except ZeroDivisionError as e:\n",
        "        print(\"Error: Cannot divide by zero\")\n",
        "        proportion_snp = 0\n",
        "        proportion_transitions = 0\n",
        "        proportion_transversions = 0\n",
        "        proportion_indels = 0\n",
        "        proportion_ins = 0\n",
        "        proportion_del = 0\n",
        "        proportion_mnp = 0\n",
        "        proportion_complex = 0\n",
        "        mutation_rate = 0\n",
        "\n",
        "    #GROUP DATA IN DICTIONARIES\n",
        "    basic_data = {\n",
        "      'Error Rate': [mutation_rate],\n",
        "      'Total consensus': [consensus_number],\n",
        "      'Sequence length': [sequence_length],\n",
        "      'Total Variants': [total_variants],\n",
        "      'Total Unique Variants': [total_unique_variants],\n",
        "      'Max barcode frequency': [max_barcode],\n",
        "      'Cutoff used': [cutoff],\n",
        "      'Threshold used': [threshold],\n",
        "      'Min position analysed': [min_pos],\n",
        "      'Max position analysed': [max_pos],\n",
        "    }\n",
        "    total_data = {\n",
        "      'Total Variants': [total_variants],\n",
        "      'Total SNP': [total_snp],\n",
        "      'Total Transitions': [total_transitions],\n",
        "      'Total Transversions': [total_transversions],\n",
        "      'Total INS': [total_ins],\n",
        "      'Total DEL': [total_del],\n",
        "      'Total Indels': [total_indels],\n",
        "      'Total MNP': [total_mnp],\n",
        "      'Total Complex': [total_complex]\n",
        "    }\n",
        "    proportion_data = {\n",
        "      'Proportion SNP': [proportion_snp],\n",
        "      'Proportion SNP Transitions': [proportion_transitions],\n",
        "      'Proportion SNP Transversions': [proportion_transversions],\n",
        "      'Proportion Indels': [proportion_indels],\n",
        "      'Proportion INS': [proportion_ins],\n",
        "      'Proportion DEL': [proportion_del],\n",
        "      'Proportion MNP': [proportion_mnp],\n",
        "      'Proportion complex': [proportion_complex]\n",
        "    }\n",
        "\n",
        "    #CREATE DATAFRAMES\n",
        "    df_grouped_by_position = dataframe.groupby('POS')[['AO', 'AO_rate', 'Variant frequency (%)']].sum().reset_index().sort_values('POS')\n",
        "    df_indels = dataframe[(dataframe[\"TYPE\"] == \"ins\") | (dataframe[\"TYPE\"] == \"del\")]\n",
        "    df_grouped_indels = df_indels.groupby('POS')[['AO', 'AO_rate', 'Variant frequency (%)']].sum().reset_index().sort_values('POS') # Group indels' AO values by position and sum them up\n",
        "    df_snps = dataframe[(dataframe[\"TYPE\"] == \"snp\")]\n",
        "    df_grouped_snp = df_snps.groupby('POS')[['AO', 'AO_rate', 'Variant frequency (%)']].sum().reset_index().sort_values('POS')\n",
        "    df_snp_types = create_df_snp_types(dict_snp_types)\n",
        "    df_basic_data = pd.DataFrame(basic_data)\n",
        "    df_total_data = pd.DataFrame(total_data)\n",
        "    df_proportion_data = pd.DataFrame(proportion_data)\n",
        "\n",
        "\n",
        "    #CREATE EXCEL FILE FROM DATAFRAMES\n",
        "    excel_file = output_prefix + '.xlsx'\n",
        "    with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
        "        dataframe.to_excel(writer, sheet_name='Raw data', index=False)\n",
        "        df_grouped_by_position.to_excel(writer, sheet_name='Variants per position', index=False)\n",
        "        df_indels.to_excel(writer, sheet_name='Indels', index=False)\n",
        "        df_grouped_indels.to_excel(writer, sheet_name='Indels per position', index=False)\n",
        "        df_snps.to_excel(writer, sheet_name='SNPs', index=False)\n",
        "        df_grouped_snp.to_excel(writer, sheet_name='SNPs per position', index=False)\n",
        "        df_snp_types.to_excel(writer, sheet_name='SNP types', index=True)\n",
        "        df_basic_data.to_excel(writer, sheet_name='Error rate', index=False)\n",
        "        df_total_data.to_excel(writer, sheet_name='Total data', index=False)\n",
        "        df_proportion_data.to_excel(writer, sheet_name='Proportion data', index=False)\n",
        "\n",
        "\n",
        "    #CREATE CSV FILE FROM DATAFRAME WITH RAW DATA\n",
        "    csv_file = output_prefix + \".csv\"\n",
        "    dataframe.to_csv(csv_file, index=False)\n",
        "\n",
        "\n",
        "    #CREATE GRAPH WITH THE DISTRIBUTION OF VARIANTS\n",
        "    plt.clf()\n",
        "    try:\n",
        "      grouped_df = dataframe.groupby('POS')['AO'].sum().reset_index().sort_values('POS') # Group AO values by position and sum them up\n",
        "    except KeyError:\n",
        "        print(\"WARNING: There is a problem with grouped_df Dataframe. The variants distribution graph will be empty.\")\n",
        "    plt.bar(grouped_df['POS'], grouped_df['AO'], color='tab:blue', label='Variants')\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Number of variants')\n",
        "    plt.title('Variants distribution')\n",
        "    plt.suptitle(output_prefix)\n",
        "    plt.legend(loc='upper right')\n",
        "    try:\n",
        "        plt.ylim([0, grouped_df['AO'].max()*1.1]) # Set y-axis limits\n",
        "    except Exception:\n",
        "        pass\n",
        "    plt.xlim(min_pos -1, max_pos + 1) # Set x-axis limits\n",
        "    variants_graph = output_prefix + \"_variants_distribution.png\"\n",
        "    plt.savefig(variants_graph)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    #CREATE GRAPH WITH THE DISTRIBUTION OF INDEL VARIANTS\n",
        "    plt.clf()\n",
        "    try:\n",
        "      plt.bar(df_grouped_indels['POS'], df_grouped_indels['AO'], color='tab:red', label='Indel variants')\n",
        "    except KeyError:\n",
        "        print(\"WARNING: There is a problem with df_grouped_indels Dataframe. The indels graph will be empty.\")\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Number of variants')\n",
        "    plt.title('Indel variants distribution')\n",
        "    plt.suptitle(output_prefix)\n",
        "    plt.legend(loc='upper right')\n",
        "    try:\n",
        "        plt.ylim([0, df_grouped_indels['AO'].max()*1.1]) # Set y-axis limits\n",
        "    except Exception:\n",
        "        pass\n",
        "    plt.xlim(min_pos -1, max_pos + 1) # Set x-axis limits\n",
        "    # Save graph\n",
        "    indels_graph = output_prefix + \"_indels_distribution.png\"\n",
        "    plt.savefig(indels_graph)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    #CREATE HEATMAP IMAGE OF THE SNP TYPES (shown as percentages)\n",
        "    plt.clf()\n",
        "    total_sum = sum(dict_snp_types.values())\n",
        "    if total_sum != 0:\n",
        "        dict_snp_types_percentage = {key: (value / total_sum) * 100 for key, value in dict_snp_types.items()}\n",
        "    else:\n",
        "        dict_snp_types_percentage = dict_snp_types\n",
        "    df_table = create_df_snp_types(dict_snp_types_percentage)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(df_table.astype(float), cmap='coolwarm', annot=True, fmt=\".1f\", cbar_kws={'label': '%'})\n",
        "    plt.gca().xaxis.set_label_position('top')\n",
        "    plt.xlabel('Nucleotide substitutions')\n",
        "    plt.ylabel('Reference nucleotides')\n",
        "    plt.suptitle(output_prefix)\n",
        "    plt.subplots_adjust(top=0.80)\n",
        "    plt.gca().tick_params(axis='x', top=True, bottom=False, labeltop=True, labelbottom=False) #Adjust position of ticks and x-axis labels\n",
        "    plt.text(0.5, -0.1, f\"Total number of substitutions: {total_sum}\", transform=plt.gca().transAxes, ha='center') #Add total number of substitutions as text in the image\n",
        "    heatmap_snp_types_graph = output_prefix + 'heatmap_snp_types.png'\n",
        "    plt.savefig(heatmap_snp_types_graph)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    return excel_file, csv_file, variants_graph, indels_graph, heatmap_snp_types_graph\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Main program\n",
        "##-------------\n",
        "\n",
        "\n",
        "## Step 1: Parameters catching\n",
        "##--------------------\n",
        "\n",
        "print(\"\\tStep 1 => Parameters catching\")\n",
        "\n",
        "# Check that the necessary variables have been provided\n",
        "assert 'input_file' and isinstance(input_file, str), \"Please provide an input file\"\n",
        "assert 'consensus_number' and isinstance(consensus_number, int), \"Please provide a consesnsus number\"\n",
        "assert 'min_pos' and isinstance(min_pos, int), \"Please provide a 'min_pos' number\"\n",
        "assert 'max_pos' and isinstance(max_pos, int), \"Please provide a 'max_pos' number\"\n",
        "assert 'variant_freq_threshold' and isinstance(variant_freq_threshold, int), \"Please provide a variant_frequency_threshold number\"\n",
        "\n",
        "vcf_file = input_file\n",
        "variant_frequency_threshold = variant_freq_threshold\n",
        "\n",
        "if not os.path.isfile(vcf_file):\n",
        "    send_error_message(f'Input file \"{vcf_file}\" of {__file__} does not exist. Please provide a valid file path.')\n",
        "\n",
        "# Check if optional variables have been provided; if not, create them and assign the value None.\n",
        "if 'max_barcode' not in globals():\n",
        "    max_barcode = None\n",
        "if 'cutoff' not in globals():\n",
        "    cutoff = None\n",
        "if 'threshold' not in globals():\n",
        "    threshold = None\n",
        "\n",
        "print(\"\\tStep 1 done\\n\")\n",
        "\n",
        "\n",
        "\n",
        "## Step 2: Creating dataframe from vcf file\n",
        "##--------------------\n",
        "\n",
        "print(\"\\tStep 2 => Creating dataframe from vcf file\")\n",
        "\n",
        "try:\n",
        "  dataframe_from_vcf = create_dataframe_from_vcf(vcf_file, consensus_number, min_pos, max_pos, variant_frequency_threshold)\n",
        "except Exception as e:\n",
        "    send_error_message(f'VCF file could not be analysed: Problem when trying to convert VCF file to pandas dataframe:\\n{e}')\n",
        "\n",
        "print(\"\\tStep 2 done\\n\")\n",
        "\n",
        "\n",
        "\n",
        "## Step 3: Extracting data from dataframe | Creating excel and csv files | Drawing graphs\n",
        "##--------------------\n",
        "\n",
        "print(\"\\tStep 3 => Extracting data from dataframe | Creating excel and csv files | Drawing graphs\")\n",
        "\n",
        "try:\n",
        "  excel_file, csv_file, variants_graph, indels_graph, heatmap_snp_types_graph = extract_data_from_dataframe(dataframe_from_vcf, output_prefix, consensus_number, min_pos, max_pos, max_barcode, cutoff, threshold)\n",
        "except Exception as e:\n",
        "    send_error_message(f'There was a problem with the extract_data_from_dataframe function:\\n{e}')\n",
        "\n",
        "print(\"\\tStep 3 done\\n\")\n",
        "\n",
        "\n",
        "print(\"\\tJOB DONE!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ozhjW99Ii8d_"
      },
      "outputs": [],
      "source": [
        "#@markdown # Show summary table\n",
        "df_basic_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KA_A997A6_Y2",
        "outputId": "e7d11d7e-f27e-4ee1-d2a4-419ad86ee83e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25865aac-7bd2-473a-b2a7-97ec827041a1\", \"NGS_HN00191375_cov0_98Q20.xlsx\", 198817)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a608e533-99e9-40ec-b33c-668e0ec01366\", \"NGS_HN00191375_cov0_98Q20.csv\", 127634)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b757808-b849-4d7f-9800-56bc2bc74e84\", \"NGS_HN00191375_cov0_98Q20_variants_distribution.png\", 24621)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c92796a8-af5b-4cb4-b532-53798d516354\", \"NGS_HN00191375_cov0_98Q20_indels_distribution.png\", 23331)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b29e99fc-adb3-4713-a331-8eb60a01aa60\", \"NGS_HN00191375_cov0_98Q20heatmap_snp_types.png\", 31272)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Download files\n",
        "files.download(excel_file)\n",
        "files.download(csv_file)\n",
        "files.download(variants_graph)\n",
        "files.download(indels_graph)\n",
        "files.download(heatmap_snp_types_graph)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}